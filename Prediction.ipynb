{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from mask_functions import rle2mask, mask2rle\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = storage.Client().get_bucket(\"pneumothorax_chest_x-rays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs = list(bucket.list_blobs(prefix='test/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6067.151787519...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6214.151787519...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6177.151787519...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6655.151787519...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6359.151787519...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             ImageId  EncodedPixels\n",
       "0  1.2.276.0.7230010.3.1.4.8323329.6067.151787519...             -1\n",
       "1  1.2.276.0.7230010.3.1.4.8323329.6214.151787519...             -1\n",
       "2  1.2.276.0.7230010.3.1.4.8323329.6177.151787519...             -1\n",
       "3  1.2.276.0.7230010.3.1.4.8323329.6655.151787519...             -1\n",
       "4  1.2.276.0.7230010.3.1.4.8323329.6359.151787519...             -1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./output/sample_submission.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "\n",
    "class TorchDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, blobs, df):\n",
    "        self.blobs = blobs\n",
    "        self.df = df\n",
    "        \n",
    "        self.image_info = collections.defaultdict(dict)\n",
    "        \n",
    "        i = 0\n",
    "        for blob in tqdm(self.blobs, total= len(self.blobs)):\n",
    "            file_path = blob.name\n",
    "            img_id = file_path.split('/')[-1][:-4]\n",
    "            \n",
    "            df_temp = self.df.loc[self.df.ImageId == img_id]\n",
    "            if not df_temp.iloc[0, 0]:\n",
    "                continue\n",
    "            \n",
    "            dcm_path = './testset/{}.dcm'.format(img_id)\n",
    "            png_path = './testset_png/{}.png'.format(img_id)\n",
    "                \n",
    "            # if the dcm is not downloaded, download it.\n",
    "            if not os.path.exists(dcm_path):\n",
    "                with open(dcm_path, 'wb') as file_obj:\n",
    "                    blob.download_to_file(file_obj)  \n",
    "            # if the png is not created, create it.\n",
    "            if not os.path.exists(png_path):\n",
    "                with open(png_path, 'wb') as file_obj:\n",
    "                    dcm_data = pydicom.dcmread(dcm_path) #, force=True)  \n",
    "                    img = dcm_data.pixel_array\n",
    "                    img_mem = Image.fromarray(img)\n",
    "                    img_mem.save(file_obj)\n",
    "                \n",
    "            self.image_info[i][\"image_id\"] = img_id\n",
    "            self.image_info[i][\"image_path\"] = png_path\n",
    "            i += 1\n",
    "                \n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        # images\n",
    "        img_path = self.image_info[idx][\"image_path\"]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        tsr = torchvision.transforms.ToTensor()(img)\n",
    "        \n",
    "#         # resize\n",
    "#         tsr = img.resize((256, 256), resample=Image.BILINEAR)\n",
    "#         tsr = torchvision.transforms.ToTensor()(tsr)\n",
    "\n",
    "        return img, tsr, self.image_info[idx][\"image_id\"]\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1372/1372 [00:01<00:00, 959.48it/s]\n"
     ]
    }
   ],
   "source": [
    "testset = TorchDataset(blobs, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "      \n",
    "def get_instance_segmentation_model(num_classes):\n",
    "    # load an instance segmentation model pre-trained on COCO\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "    # get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # now get the number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    # and replace the mask predictor with a new one\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
    "                                                       hidden_layer,\n",
    "                                                       num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskRCNN(\n",
       "  (transform): GeneralizedRCNNTransform()\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d()\n",
       "      (relu): ReLU(inplace)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign()\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "    (mask_roi_pool): MultiScaleRoIAlign()\n",
       "    (mask_head): MaskRCNNHeads(\n",
       "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu1): ReLU(inplace)\n",
       "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu2): ReLU(inplace)\n",
       "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu3): ReLU(inplace)\n",
       "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu4): ReLU(inplace)\n",
       "    )\n",
       "    (mask_predictor): MaskRCNNPredictor(\n",
       "      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (relu): ReLU(inplace)\n",
       "      (mask_fcn_logits): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# our dataset has two classes only - background and person\n",
    "num_classes = 2\n",
    "\n",
    "# get the model using our helper function\n",
    "model = get_instance_segmentation_model(num_classes)\n",
    "\n",
    "# load the trained parameter\n",
    "model.load_state_dict(torch.load('./model/model_para.pt'))\n",
    "# model.load_state_dict(torch.load('./model/model.bin'))\n",
    "\n",
    "# move model to the right device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick one image from the test set\n",
    "img, tsr, img_id = testset[0]\n",
    "# put the model in evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model([tsr.to(device)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'boxes': tensor([[738.3564, 686.0402, 947.3710, 820.5953],\n",
       "          [653.8806, 166.7901, 868.2126, 315.7506],\n",
       "          [645.6188, 170.7451, 819.5466, 261.4549],\n",
       "          [291.6364, 157.6022, 480.4015, 247.2645],\n",
       "          [636.6669, 165.9051, 903.5880, 420.8497],\n",
       "          [329.5251, 157.8419, 483.0401, 212.4015],\n",
       "          [721.7000, 547.8616, 958.2328, 846.8204],\n",
       "          [794.3271, 730.5885, 942.1921, 818.4711],\n",
       "          [660.4969, 170.4238, 785.6829, 225.6550]], device='cuda:0'),\n",
       "  'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'),\n",
       "  'scores': tensor([0.9118, 0.5199, 0.4351, 0.2853, 0.1884, 0.1615, 0.1222, 0.0736, 0.0633],\n",
       "         device='cuda:0'),\n",
       "  'masks': tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0')}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9118, 0.5199, 0.4351, 0.2853, 0.1884, 0.1615, 0.1222, 0.0736, 0.0633],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = prediction[0]['scores']\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_binary = (scores >0.3)\n",
    "scores_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_binary.all == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = prediction[0]['scores']\n",
    "scores_binary = (scores >= 0.3)\n",
    "\n",
    "# no score/mask or all the scores <0.3\n",
    "if len(scores) ==0 or scores_binary.all == 0:\n",
    "    rle = '-1'\n",
    "\n",
    "else:\n",
    "    masks = prediction[0]['masks'].mul(255).byte().cpu().numpy()\n",
    "    mask_pred = np.zeros_like(masks[0, 0]).astype(np.uint64) #change type to prevent overflow\n",
    "    for i, binary in enumerate(scores_binary):\n",
    "        if binary ==1:\n",
    "            mask_pred += masks[i, 0]\n",
    "    mask_pred = (mask_pred > 127).astype(np.uint8)\n",
    "    mask_pred = np.where(mask_pred ==0, 0, 255)\n",
    "    rle = mask2rle(mask_pred.T, 1024, 1024)\n",
    "    \n",
    "#     # resize\n",
    "#     mask_temp = Image.fromarray(mask_pred).resize((1024, 1024), resample=Image.BILINEAR)\n",
    "#     mask_temp = np.array(mask_temp)\n",
    "#     rle = mask2rle(mask_temp.T, 1024, 1024)\n",
    "    \n",
    "    if rle == '':\n",
    "        rle = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'663788 13 1010 15 1002 24 994 32 989 36 985 40 982 43 978 48 973 52 970 54 969 56 965 59 963 61 962 62 960 65 957 67 949 3 3 69 947 6 1 70 943 81 942 83 940 84 940 84 939 86 937 89 935 91 931 94 929 95 929 95 928 96 928 96 927 97 927 97 926 98 926 97 927 96 928 96 928 95 929 92 932 92 932 92 931 93 931 92 932 92 932 92 932 92 932 91 933 91 933 91 933 90 934 90 934 90 934 89 935 89 935 88 935 89 935 88 936 88 936 87 937 85 939 82 942 80 944 78 946 77 947 68 5 3 948 68 957 67 957 67 957 67 957 67 957 66 958 66 958 66 958 65 959 65 959 65 959 64 960 64 960 64 960 63 961 62 962 62 962 61 964 59 965 59 965 59 965 58 966 58 966 57 968 56 968 56 968 55 969 55 969 55 550 12 408 53 549 16 406 53 548 16 407 53 547 17 407 53 546 18 408 52 544 19 409 52 543 20 409 52 542 21 410 50 542 22 410 50 541 22 411 50 540 22 413 49 539 23 413 49 538 23 414 49 537 24 415 48 537 24 415 48 536 24 416 48 535 25 417 47 534 25 419 46 533 26 419 46 532 26 421 45 531 27 421 45 530 27 423 44 530 27 423 44 529 27 425 43 528 28 425 44 527 28 425 44 526 28 427 43 526 28 427 43 525 28 429 43 523 29 430 42 523 29 430 42 522 29 432 41 521 30 432 41 520 31 433 41 518 31 434 42 516 32 435 41 516 32 436 41 514 33 436 42 512 33 438 42 511 33 438 43 509 34 439 43 508 33 440 43 507 34 441 43 505 35 442 43 503 35 443 43 503 35 444 43 501 36 445 42 500 37 445 43 498 38 446 43 496 38 447 44 494 39 448 45 492 39 449 47 488 40 449 48 487 40 450 49 484 41 451 50 481 41 453 50 479 42 454 51 477 42 454 53 474 43 455 53 472 44 456 53 471 44 456 54 469 44 458 54 467 45 459 54 466 45 460 60 458 46 461 62 454 47 462 62 453 47 463 62 451 48 464 61 451 48 465 61 450 48 466 60 449 49 467 59 449 48 469 59 447 49 470 58 446 50 471 57 446 50 472 56 445 51 474 54 444 52 475 53 444 52 476 52 443 53 478 50 442 54 479 50 441 54 482 47 441 54 484 45 440 55 486 43 440 55 486 44 438 55 488 43 438 55 489 43 437 55 490 43 435 56 491 42 435 56 493 41 434 56 494 40 433 57 495 40 432 57 496 39 431 58 497 38 431 58 498 38 430 58 499 37 430 58 500 37 428 59 501 36 428 59 503 35 427 59 504 34 427 60 504 34 426 60 505 33 426 60 506 33 425 60 507 33 424 60 509 31 424 60 510 31 423 60 512 30 422 60 513 29 423 59 515 28 422 59 516 28 421 59 517 27 422 58 518 27 421 58 520 26 420 58 521 26 420 58 521 26 419 58 522 27 417 58 523 27 417 57 525 25 417 57 527 24 416 57 529 22 417 57 530 20 417 57 532 18 418 56 534 16 418 56 536 15 417 56 537 14 418 56 968 56 968 56 969 56 968 56 969 55 970 54 971 54 971 53 972 52 973 51 973 52 973 51 974 50 974 51 974 50 974 50 975 50 974 50 975 49 976 48 976 49 976 48 976 48 977 47 978 46 979 46 980 44 981 44 980 45 980 44 981 44 980 45 980 44 980 45 980 44 980 45 980 45 980 44 982 43 982 42 983 42 983 41 983 42 983 42 983 41 983 42 983 42 983 41 984 41 985 40 985 40 985 40 985 40 985 39 986 39 986 39 986 39 985 40 985 40 985 39 986 39 987 38 987 38 987 38 987 37 988 37 988 37 989 35 990 35 991 34 991 34 991 33 993 31 995 29 997 27 1000 24 1004 20 1007 18 1010 14 1013 9'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(mask_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.ylabel('MASKED')\n",
    "\n",
    "plt.imshow(img, cmap=plt.cm.bone)\n",
    "plt.imshow(mask_pred, alpha=0.3, cmap=\"Reds\")\n",
    "# plt.imshow(mask_temp, alpha=0.3, cmap=\"Greens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the test set\n",
    "# put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_list = list()\n",
    "    \n",
    "    for i in tqdm(range(len(testset))):\n",
    "        img, tsr, img_id = testset[i]\n",
    "        prediction = model([tsr.to(device)])\n",
    "###\n",
    "        scores = prediction[0]['scores']\n",
    "        scores_binary = (scores >= 0.3)\n",
    "\n",
    "        # no score/mask or all the scores <0.3\n",
    "        if len(scores) ==0 or scores_binary.all == 0:\n",
    "            rle = '-1'\n",
    "\n",
    "        else:\n",
    "            masks = prediction[0]['masks'].mul(255).byte().cpu().numpy()\n",
    "            mask_pred = np.zeros_like(masks[0, 0]).astype(np.uint64) #change type to prevent overflow\n",
    "            for i, binary in enumerate(scores_binary):\n",
    "                if binary ==1:\n",
    "                    mask_pred += masks[i, 0]\n",
    "            mask_pred = (mask_pred > 127).astype(np.uint8)\n",
    "            mask_pred = np.where(mask_pred ==0, 0, 255)\n",
    "            rle = mask2rle(mask_pred.T, 1024, 1024)\n",
    "\n",
    "        #     # resize\n",
    "        #     mask_temp = Image.fromarray(mask_pred).resize((1024, 1024), resample=Image.BILINEAR)\n",
    "        #     mask_temp = np.array(mask_temp)\n",
    "        #     rle = mask2rle(mask_temp.T, 1024, 1024)\n",
    "\n",
    "            if rle == '':\n",
    "                rle = '-1'\n",
    "###\n",
    "    \n",
    "        test_list.append([img_id, rle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_order = list(df['ImageId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = [tuple for x in sample_order for tuple in test_list if tuple[0] == x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(pred_list, columns = df.columns.values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.to_csv('./output/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
